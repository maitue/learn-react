{"ast":null,"code":"import { __extends } from \"tslib\";\nimport { StartSegmentDetectionRequest, StartSegmentDetectionResponse } from \"../models/models_0\";\nimport { deserializeAws_json1_1StartSegmentDetectionCommand, serializeAws_json1_1StartSegmentDetectionCommand } from \"../protocols/Aws_json1_1\";\nimport { getSerdePlugin } from \"@aws-sdk/middleware-serde\";\nimport { Command as $Command } from \"@aws-sdk/smithy-client\";\n/**\n * <p>Starts asynchronous detection of segment detection in a stored video.</p>\n *          <p>Amazon Rekognition Video can detect segments in a video stored in an Amazon S3 bucket. Use <a>Video</a> to specify the bucket name and\n *       the filename of the video. <code>StartSegmentDetection</code> returns a job identifier (<code>JobId</code>) which you use to get\n *       the results of the operation. When segment detection is finished, Amazon Rekognition Video publishes a completion status to the Amazon Simple Notification Service topic\n *       that you specify in <code>NotificationChannel</code>.</p>\n *          <p>You can use the <code>Filters</code> (<a>StartSegmentDetectionFilters</a>)\n *       input parameter to specify the minimum detection confidence returned in the response.\n *       Within <code>Filters</code>, use <code>ShotFilter</code> (<a>StartShotDetectionFilter</a>)\n *       to filter detected shots. Use  <code>TechnicalCueFilter</code> (<a>StartTechnicalCueDetectionFilter</a>)\n *       to filter technical cues. </p>\n *          <p>To get the results of the segment detection operation, first check that the status value published to the Amazon SNS\n *       topic is <code>SUCCEEDED</code>. if so, call <a>GetSegmentDetection</a> and pass the job identifier (<code>JobId</code>)\n *       from the initial call to <code>StartSegmentDetection</code>. </p>\n *\n *\n *          <p>For more information, see Detecting Video Segments in Stored Video in the Amazon Rekognition Developer Guide.</p>\n */\n\nvar StartSegmentDetectionCommand =\n/** @class */\nfunction (_super) {\n  __extends(StartSegmentDetectionCommand, _super); // Start section: command_properties\n  // End section: command_properties\n\n\n  function StartSegmentDetectionCommand(input) {\n    var _this = // Start section: command_constructor\n    _super.call(this) || this;\n\n    _this.input = input;\n    return _this; // End section: command_constructor\n  }\n  /**\n   * @internal\n   */\n\n\n  StartSegmentDetectionCommand.prototype.resolveMiddleware = function (clientStack, configuration, options) {\n    this.middlewareStack.use(getSerdePlugin(configuration, this.serialize, this.deserialize));\n    var stack = clientStack.concat(this.middlewareStack);\n    var logger = configuration.logger;\n    var clientName = \"RekognitionClient\";\n    var commandName = \"StartSegmentDetectionCommand\";\n    var handlerExecutionContext = {\n      logger: logger,\n      clientName: clientName,\n      commandName: commandName,\n      inputFilterSensitiveLog: StartSegmentDetectionRequest.filterSensitiveLog,\n      outputFilterSensitiveLog: StartSegmentDetectionResponse.filterSensitiveLog\n    };\n    var requestHandler = configuration.requestHandler;\n    return stack.resolve(function (request) {\n      return requestHandler.handle(request.request, options || {});\n    }, handlerExecutionContext);\n  };\n\n  StartSegmentDetectionCommand.prototype.serialize = function (input, context) {\n    return serializeAws_json1_1StartSegmentDetectionCommand(input, context);\n  };\n\n  StartSegmentDetectionCommand.prototype.deserialize = function (output, context) {\n    return deserializeAws_json1_1StartSegmentDetectionCommand(output, context);\n  };\n\n  return StartSegmentDetectionCommand;\n}($Command);\n\nexport { StartSegmentDetectionCommand };","map":null,"metadata":{},"sourceType":"module"}